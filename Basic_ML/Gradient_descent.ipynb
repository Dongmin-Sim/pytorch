{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edwith의 부스트 코스 : \"파이토치로 시작하는 딥러닝 기초\" 를 바탕으로 작성되었습니다.  \n",
    "https://www.boostcourse.org/ai214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent\n",
    "- Hypothesis function\n",
    "- data 확인\n",
    "- Cost funcion\n",
    "- Gradient descent 이론 및 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis function\n",
    "가설이론, 이는 인공 신경망의 구조를 나타내는데 입력되는 input_x 에 대해 output_y 를 예측하며 H(x) 로 표현 함. \n",
    "$$H(x) = Wx + b$$\n",
    "여기서 W는 하나의 matrix 이고, 이것이 x 라는 input 벡터에 곱해진 후 b 라는 bias 벡터에 더해져 H(x)를 계산함.  \n",
    "이것은 아주 간단한 1차 함수 모델이며, W, b 라는 변수를 학습(업데이트)하면서 주어진 데이터에 model 을 최적화 하는 것이라고 볼 수 있음.  \n",
    "PyTorch 에서는 zeros 로 초기화 한 후 H(x) 를 다음과 같이 표현 할 수 있음. \n",
    "\n",
    "```python \n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "hypothesis = x_train * W + b\n",
    "```\n",
    "Gradient descent를 이해하기 위해 bias 가 없는 W 만으로 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Data\n",
    "최대한 간단한 dataset 을 준비함, 입력으로는 1, 2, 3, 출력으로는 1, 2, 3 을 가지는 텐서이며  \n",
    "이 데이터셋의 입출력의 값이 같으므로 최적의 H(x) = 1 * x_train 일 것임. 즉, W가 1일때 데이터셋 에 있는 모든 데이터를 정확하게 예측할 수 있음.  \n",
    "결국 W를 1이 아닌 어떠한 값에서 1로 수렴시키는 것이 학습 목표라고 할 수 있음. W 가 1에 가까울 수록 주어진 데이터에서 정확한 모델이 되는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "모델의 좋고 나쁨, 얼마나 잘 예측하는지를 평가하기 위해서 cost function을 정의하게 됨.  \n",
    "cost function 은 모델 예측값이 실제 데이터와 얼마나 다른지를 나타내는 값을 산출하는 함수이며 결과로 나온 cost 가 낮을 수록 좋은 모델임.  \n",
    "본 데이터 셋에서는 W가 1일 수록 cost는 0에 가까워 질 것이며, W가 1에서 멀어질 수록 cost 값은 커지게 될 것임.  \n",
    "\n",
    "보통 Linear regression 에서는 cost function 을 MSE 를 주로 사용함. \n",
    "\n",
    "결론적으로 W를 잘 업데이트 시키기 위해서는 cost funcion 을 최소화해야함. cost function 값을 최소화 시키려면 기울기가 음수일때 W 값은 더 커저야 하고, 기울기가 양수일 경우에는 W 가 작아져야 함.  \n",
    "또 기울기가 가파를 수록 cost 가 큰 것이기 때문에 W를 크게 바꾸고, 수평에 가까울수록 cost 가 0에 가까운 것이니 W를 조금씩 바꿔야 함.  \n",
    "이러한 기울기를 Gradient 라고 함.  \n",
    "\n",
    "$$\\dfrac{\\partial  cost}{\\partial  W} = \\triangledown W $$\n",
    "\n",
    "Gradient 를 계산하려면 이를 미분해야하는데 cost function 은 W에 대한 2차 함수이므로 간단한 미분 방정식을 통해 계산이 가능함. 편미분  \n",
    "cost 를 줄일려면 W 를 Grad W값에 일정한 상수 a 를 곱한 후 빼면 됨. 여기에서 상수 a 를 learing weight 라고 부르면 lr 라고 줄여씁니다.\n",
    "\n",
    "$$\\triangledown W = \\dfrac{\\partial cost}{\\partial W} = \\dfrac{2}{m} \\sum^{m}_{i=1} (Wx^{(i)} - y^{(i)})x^{(i)} $$\n",
    "\n",
    "이것이 Gradient descent 라고 함. Gradient 를 이용해서 Cost 를 줄인다는 뜻."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행하게 되는데 데이터셋을 정의하고 모델을 초기화함.  \n",
    "그후 H(x) 를 계산하게 되고, cost function 값과 gradient 를 계산한 후 Gradient descent하는 과정을 반복하게 되는데  \n",
    "이렇게 반복할때마다 전제 dataset 를 사용하는 횟수를 Epoch 이라고함. \n",
    "\n",
    "PyTorch 에서는 gradien desent 를 더욱 쉽게 구현할 수 있도록 torch.optim 이라는 라이브러리를 제공해줌.  \n",
    "이를 사용하려면 optimizer를 학습가능한 변수와 학습률 lr 를 설정 및 정의해주고 다음의 코드로 계산함.  \n",
    "```python \n",
    "\n",
    "```\n",
    "이 3줄을 통해서 optimizer는 W의 gradient를 저장한 후, W의 값을 gradient 에 맞게 업데이트하게 됨.\n",
    "\n",
    "optimizer.zero_grad() 함수는 optimizer 에 저장되어있는 모든 학습 가능한 변수의 gradient 를 전부 0으로 초기화  \n",
    "cost.backward()는 cost function 을 미분해서 각 변수들의 gradient를 채움.  \n",
    "optimizer.step()으로 저장된 gradient 값으로 gradient descent를 시행함.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    1/10 W: 0.000 Cost : 4.666667\n",
      "Epoch :    2/10 W: 1.400 Cost : 0.746667\n",
      "Epoch :    3/10 W: 0.840 Cost : 0.119467\n",
      "Epoch :    4/10 W: 1.064 Cost : 0.019115\n",
      "Epoch :    5/10 W: 0.974 Cost : 0.003058\n",
      "Epoch :    6/10 W: 1.010 Cost : 0.000489\n",
      "Epoch :    7/10 W: 0.996 Cost : 0.000078\n",
      "Epoch :    8/10 W: 1.002 Cost : 0.000013\n",
      "Epoch :    9/10 W: 0.999 Cost : 0.000002\n",
      "Epoch :   10/10 W: 1.000 Cost : 0.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([W], lr=0.15)\n",
    "\n",
    "nb_epochs = 10\n",
    "\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    hypothesis = W * x_train\n",
    "    \n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    print('Epoch : {:4d}/{} W: {:.3f} Cost : {:.6f}'.format(epoch, nb_epochs, W.item(), cost.item()))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
