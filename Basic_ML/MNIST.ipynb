{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edwith의 부스트 코스 : \"파이토치로 시작하는 딥러닝 기초\" 를 바탕으로 작성되었습니다.  \n",
    "https://www.boostcourse.org/ai214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "- MNIST\n",
    "- Full code : MNIST classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "MNIST dataset 은 손으로 쓰인 dataset 임. 0~9까지의 숫자이미지로 구성이 되어있음.  \n",
    "6만장의 이미지와 라벨로 이루어진 training dataset, 1만장의 이미지와 그에 해당하는 레이블로 이루어진 test dataset 이 있음.    \n",
    "\n",
    "28 * 28 사이즈의 channel 값이 1인 gray scale의 이미지임. 레이블은 one-hot encoded 되지 않음.  \n",
    "784개의 값들로 이루어진 이미지라고 할 수 있음.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision \n",
    "PyTorch 에서 사용하는 패키지로 유명한 dataset, 모델 architecture 들, 데이터에 적용될 수 있는 transform(preprocessing) 들로 구성되어 있고, dataset들을 쉽게 읽어올 수 있도록 torchvision.utils 라는 패키지 또한 제공함.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code : MNIST classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch / Batch size / Iteration\n",
    "* one **epoch** = one forward pass and one backward pass of all the training examples (training set 전체에 대해 순전파와 역전파가 일어났을때는 1에폭이라고함, training set 전체가 사용되었을때 1에폭)\n",
    "* **batch size** = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need. (한번의 forward/backward 에 사용되는 훈련 데이터의 수, 전체 set을 나누어 학습을 진행할때 나누는 batch의 사이즈)\n",
    "* number of **iterations** = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes). (배치를 몇번 학습에 사용되었는지, 학습에 사용된 횟수)\n",
    "\n",
    "**Example** : if you have 1000 training example, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.  \n",
    "1 epoch  = number of training example = batch size * iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(784, 10, bias=True).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    1/15, Cost : 0.535469, ACC:0.8677327036857605\n",
      "Epoch :    2/15, Cost : 0.359274, ACC:0.9007329344749451\n",
      "Epoch :    3/15, Cost : 0.331188, ACC:0.9077996611595154\n",
      "Epoch :    4/15, Cost : 0.316578, ACC:0.9118829965591431\n",
      "Epoch :    5/15, Cost : 0.307158, ACC:0.9143326282501221\n",
      "Epoch :    6/15, Cost : 0.300181, ACC:0.9162165522575378\n",
      "Epoch :    7/15, Cost : 0.295130, ACC:0.9181332588195801\n",
      "Epoch :    8/15, Cost : 0.290852, ACC:0.9189333319664001\n",
      "Epoch :    9/15, Cost : 0.287417, ACC:0.9197498559951782\n",
      "Epoch :   10/15, Cost : 0.284380, ACC:0.9202662706375122\n",
      "Epoch :   11/15, Cost : 0.281825, ACC:0.9217662215232849\n",
      "Epoch :   12/15, Cost : 0.279801, ACC:0.9218328595161438\n",
      "Epoch :   13/15, Cost : 0.277809, ACC:0.9227167963981628\n",
      "Epoch :   14/15, Cost : 0.276154, ACC:0.923149585723877\n",
      "Epoch :   15/15, Cost : 0.274441, ACC:0.9240496754646301\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 15\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    avg_cost = 0\n",
    "    avg_acc = 0\n",
    "    total_batch = len(train_loader)\n",
    "    \n",
    "    for x_train, y_train in train_loader:\n",
    "        x_train = x_train.view(-1, 28 * 28).to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        \n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        cost = F.cross_entropy(prediction, y_train).to(device)\n",
    "        \n",
    "        correct_prediction = torch.argmax(prediction, 1) == y_train\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        avg_acc += accuracy/total_batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch\n",
    "        \n",
    "    print('Epoch : {:4d}/{}, Cost : {:.6f}, ACC:{:.5f}'.format(epoch, nb_epochs, avg_cost, avg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10])\n",
      "Accuracy :  0.8863000273704529\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # gradient 계산을 하지 않는 다는 의미 \n",
    "    x_test = mnist_test.data.view(-1, 28 * 28).float().to(device)\n",
    "    y_test = mnist_test.targets.to(device)\n",
    "    \n",
    "    prediction = model(x_test)\n",
    "    print(prediction.shape)\n",
    "    \n",
    "#     correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "    correct_prediction = torch.max(prediction, 1)[1] == y_test\n",
    "    \n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"Accuracy : \", accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :  9\n",
      "Prediction :  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = random.randint(0, len(mnist_test) - 1)\n",
    "x_single_data = mnist_test.data[r].view(-1, 28 * 28).float().to(device)\n",
    "y_single_data = mnist_test.targets[r].to(device)\n",
    "\n",
    "print('Label : ', y_single_data.item())\n",
    "single_prediction = model(x_single_data)\n",
    "print('Prediction : ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "plt.imshow(mnist_test.data[r].view(-1, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
